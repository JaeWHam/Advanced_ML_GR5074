{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Welcome to Jae Ham's repository. Please find the link to each of my project's notebook along with a brief description of each project below. All of these projects were completed for the Projects in Advanced Machine Learning class at Columbia University for the Spring term of 2020.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 1: World Happiness Prediction Model\n",
    "\n",
    "#### Data Used: United National World Happiness Report 2019\n",
    "The data used was sourced from the United Nations World Happiness Report for the year 2019. As the name suggests, the data primarily ranks the state of happiness for every country in the world by weighing the following six factors: economic production, social support, life expectancy, freedom, absence of corruption and generosity. For this particular project, the country variable was replaced with continent labels.\n",
    "\n",
    "#### Methodology\n",
    "The purpose of this project is to build a predictive model that can accurately predict a happiness level given the following input: economic production, social support, life expectancy, freedom, absence of corruption, generosity, and geographical region. WIth that in mind, Jae first wanted to understand the relationship between each of the independent variable with the target variable, and conducted a bivariate analysis via visualization and heatmap. Next, he more closely examined the importance of each feature by using Logistic Regression and Random Forest Classifier as the models that allow for automatic feature selection. Finally, he preprocessed the data, and fit on three different models. In the end, the best model was chosen.\n",
    "\n",
    "#### Modelling\n",
    "Keras Neural Network, Random Forest Classifier and K Neighbors Classifier were ran to predict the happiness level. The relevant parameters of each model were tuned using GridSearchCV, and were assessed on the training test set. The best model was chosen based on its accuracy, F1, precision and recall scores.\n",
    "\n",
    "#### Link to Project on Github:\n",
    "https://github.com/JaeWHam/Advanced_ML_GR5074/blob/master/HW1/GR5074_Assignment1_JaeHam.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 2: Brain Tumor Diagnostic MRI Image Data\n",
    "\n",
    "#### Data Used: Brain Tumor Dataset\n",
    "This dataset contains 253 images of MRI scans of the human brain, and it is split between those with tumors and those without.\n",
    "\n",
    "#### Methodology\n",
    "The purpose of this project is to build a prediction model to accurately predict the presence of a tumor given a MRI scan. Before diving into the modelling process, the data was first explored by visualizing a sample set of images that have a tumor and those without. Then, the data was appropriately preprocessed to fit for three different models.\n",
    "\n",
    "#### Modelling\n",
    "The first model was a typical vanilla neural network model. The second model was a transfer learning model that was implemented using VGG16 as the base. For the third model, a transfer learning approach was also used, but with Inception + Resnet as the base model. Then, the best model was further improved by taking the following steps. First, the best model would be saved using model checkpoint feature in relation to its highest validation accuracy score. The percentage of the freezed layer would also be tuned based on the following range: 100%, 75%, 50%, 25%. This process would all be evaluated based on the model's accuracy, F1, precision and recall scores.\n",
    "\n",
    "#### Link to Project on Github:\n",
    "https://github.com/JaeWHam/Advanced_ML_GR5074/blob/master/HW2/GR5074_Assignment2_JaeHam.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 3: BBC Text Classification\n",
    "\n",
    "#### Data Used: BBC News Dataset\n",
    "This dataset scraped 2225 articles that BBC published. It features the text of the article, and the category of which the article was published under. There are a total of five categories, which are tech, business, sport, entertainment, and politics.\n",
    "\n",
    "#### Methodology\n",
    "The purpose of this project is to build a predictive model that can accurately categorize any given text based on 5 categories. Before building the models, Jae wanted to first understand the distribution of the target variable. This was done using a histogram. Next, the data was preprocessed so that the sequence of each article is equal in its length. Finally, the data was fitted to 5 different sequential models.\n",
    "\n",
    "#### Modelling\n",
    "The data was fitted to each of the following model architecture: <br>\n",
    "1) Model A: embedding layer and dense layer <br>\n",
    "2) Model B: embedding layer with conv1d layers <br>\n",
    "3) Model C: embedding layer with one sequential layer <br>\n",
    "4) Model D: embedding layer with stacked sequential layers <br>\n",
    "5) Model E: embedding layer with bidirectional sequential layers <br>\n",
    "\n",
    "The best model was chosen and further tuned to improve its predictive power. On one hand, the number of features the embedding layer will have for each word was tuned. On the other hand, the number of features inputs for the sequential layer was also tuned. Apart from tuning its relevant parameters, Jae also experimented with the overall architecture of the best model by using a combination of sequential and convolutional layers, as well as comparing the model performance between manually tuned embedding layer and pretrained embedding from Glove. The results from each step was evaluated based on its test score and accuracy.\n",
    "\n",
    "#### Link to Project on Github:\n",
    "https://github.com/JaeWHam/Advanced_ML_GR5074/blob/master/HW3/GR5074_Assignment3_JaeHam.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Projects\n",
    "Please refer to my personal repository for a greater selection of my projects that were done in both Python and R below outside of this class. This personal repository was created previously for employment purposes. <br>\n",
    "https://github.com/jaewoongham/worksamples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
